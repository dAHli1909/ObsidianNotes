202403021558
Status: #frag
Tags: [[JHLI]][[Computaci√≥n]]

# The K Means Algorithm

The lack of tagged data encourages taking appropriate measures based on knowledge discovery approaches. Machine Learning (ML) can be broadly classified into two: supervised and unsupervised learning.

Clustering is central to many data-driven applications and is considered an
interesting and important task in machine learning. It is also studied in statistics, pattern recognition, computational geometry, bioinformatics, optimization, image processing, and in a variety of other fields . A plethora of clustering techniques have been invented in the last decade, which are being applied in a wide range of application domains

Clustering with different k values will eventually produce different
results. Different initialization problems that were analyzed in recent studies did not consider the problem where the algorithm only converges to a poor local minima. In , an alternative approach was adopted to prevent the k-means algorithm from being easily affected by noise and outlier values.
The authors presented a modified k-means algorithm based on self-paced learning theory.

The authors in [42] proposed an improvement to the vanilla k-means algorithm that prevents it from getting stuck to a local minima. The improved algorithm incorporates cuckoo search along with the k-means algorithm.

In a wide range of application domains, data analysis tasks heavily rely on clustering. This paper focused on the popular k-means algorithm and the issues of initialization and inability to handle data with mixed types of features. Unlike other review or survey papers, this paper contains both a critical analysis of the existing literature and an experimental analysis on half a dozen benchmark datasets to demonstrate the performances of different variants of k-means.

# References:
- [[The k-means Algorithm: A Comprehensive Survey and Performance Evaluation]]
